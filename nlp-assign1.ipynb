{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10793805,"sourceType":"datasetVersion","datasetId":6698546}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Context-sensitive Spelling Correction\n\nThe goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n\nSubmit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n\nUseful links:\n- [Norvig's solution](https://norvig.com/spell-correct.html)\n- [Norvig's dataset](https://norvig.com/big.txt)\n- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n\nGrading:\n- 60 points - Implement spelling correction\n- 20 points - Justify your decisions\n- 20 points - Evaluate on a test set\n","metadata":{"id":"DIgM6C9HYUhm"}},{"cell_type":"markdown","source":"## Implement context-sensitive spelling correction\n\nYour task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n\nThe best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n\nWhen solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n\n- solving a problem of n-grams frequencies storing for a large corpus;\n- taking into account keyboard layout and associated misspellings;\n- efficiency improvement to make the solution faster;\n- ...\n\nPlease don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n\n##### IMPORTANT:  \nYour project should not be a mere code copy-paste from somewhere. You must provide:\n- Your implementation\n- Analysis of why the implemented approach is suggested\n- Improvements of the original approach that you have chosen to implement","metadata":{"id":"x-vb8yFOGRDF"}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom collections import Counter, defaultdict\nimport math\n\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:30:14.766311Z","iopub.execute_input":"2025-02-19T13:30:14.766705Z","iopub.status.idle":"2025-02-19T13:30:16.751351Z","shell.execute_reply.started":"2025-02-19T13:30:14.766672Z","shell.execute_reply":"2025-02-19T13:30:16.750263Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import requests\n\nurl='https://norvig.com/big.txt'\n\n\ntry:\n    response = requests.get(url)\n    response.raise_for_status()\nexcept requests.exceptions.RequestException as e:\n    print(f\"Error fetching data: {e}\")\n    exit()\n\ntext_content = response.text","metadata":{"id":"MoQeEsZvHvvi","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:58:50.772043Z","iopub.execute_input":"2025-02-19T13:58:50.772371Z","iopub.status.idle":"2025-02-19T13:58:51.770473Z","shell.execute_reply.started":"2025-02-19T13:58:50.772347Z","shell.execute_reply":"2025-02-19T13:58:51.769566Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"import re\n\nsentences=[]\nfor i in text_content.split('.'):\n    i = re.sub(r'[^a-zA-Z\\s]', '', i).lower().replace('\\n', '')\n    tokens = word_tokenize(i)\n    if tokens:\n        sentences.append(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:58:52.070758Z","iopub.execute_input":"2025-02-19T13:58:52.071128Z","iopub.status.idle":"2025-02-19T13:59:00.735216Z","shell.execute_reply.started":"2025-02-19T13:58:52.071098Z","shell.execute_reply":"2025-02-19T13:59:00.734023Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# Tokenize the text into words\nwords = [word for sentence in sentences for word in sentence if word]\n\n# Build unigram, bigram, and trigram counts\nunigram_counts = Counter(words)\nbigram_counts = Counter(zip(words, words[1:]))\ntrigram_counts = Counter(zip(words, words[1:], words[2:]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:59:00.736698Z","iopub.execute_input":"2025-02-19T13:59:00.736987Z","iopub.status.idle":"2025-02-19T13:59:02.519681Z","shell.execute_reply.started":"2025-02-19T13:59:00.736963Z","shell.execute_reply":"2025-02-19T13:59:02.518586Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"bigrams=''\nwith open('/kaggle/input/ngrams/bigrams.txt', 'r', encoding='utf-8', errors='replace') as f:\n    bigrams=f.read().replace('\\t', ' ').split('\\n')\n\nnew_bi={}\nwords_new = []\nfor i in bigrams:\n    num, w1, w2 = i.split()\n    words_new.append(w1)\n    words_new.append(w2)\n    new_bi[(w1, w2)] = int(num)\n    \nbigram_counts = bigram_counts + Counter(new_bi)\nunigram_counts = unigram_counts + Counter(words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:59:02.521663Z","iopub.execute_input":"2025-02-19T13:59:02.521983Z","iopub.status.idle":"2025-02-19T13:59:06.182977Z","shell.execute_reply.started":"2025-02-19T13:59:02.521955Z","shell.execute_reply":"2025-02-19T13:59:06.181585Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# from https://norvig.com/spell-correct.html\ndef edits1(word):\n    \"\"\"Generate all edits that are one edit away from `word`.\"\"\"\n    letters = 'abcdefghijklmnopqrstuvwxyz'\n    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n    deletes = [L + R[1:] for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n    inserts = [L + c + R for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2(word):\n    \"\"\"Generate all edits that are two edits away from `word`.\"\"\"\n    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n\ndef known(words):\n    \"\"\"Return the subset of `words` that appear in the dictionary.\"\"\"\n    return set(w for w in words if w in unigram_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:59:06.184808Z","iopub.execute_input":"2025-02-19T13:59:06.185151Z","iopub.status.idle":"2025-02-19T13:59:06.245959Z","shell.execute_reply.started":"2025-02-19T13:59:06.185123Z","shell.execute_reply":"2025-02-19T13:59:06.244629Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"keyboard_layout = {\n    'q': ['w', 'a'], 'w': ['q', 'e', 's'], 'e': ['w', 'r', 'd'], 'r': ['e', 't', 'f'],\n    't': ['r', 'y', 'g'], 'y': ['t', 'u', 'h'], 'u': ['y', 'i', 'j'], 'i': ['u', 'o', 'k'],\n    'o': ['i', 'p', 'l'], 'p': ['o'], 'a': ['q', 's', 'z'], 's': ['w', 'a', 'd', 'x'],\n    'd': ['e', 's', 'f', 'c'], 'f': ['r', 'd', 'g', 'v'], 'g': ['t', 'f', 'h', 'b'],\n    'h': ['y', 'g', 'j', 'n'], 'j': ['u', 'h', 'k', 'm'], 'k': ['i', 'j', 'l'],\n    'l': ['o', 'k'], 'z': ['a', 'x'], 'x': ['s', 'z', 'c'], 'c': ['d', 'x', 'v'],\n    'v': ['f', 'c', 'b'], 'b': ['g', 'v', 'n'], 'n': ['h', 'b', 'm'], 'm': ['j', 'n']\n}\n\ndef keyboard_edits(word):\n    \"\"\"Generate edits based on keyboard layout.\"\"\"\n    edits = []\n    for i in range(len(word)):\n        for neighbor in keyboard_layout.get(word[i], []):\n            edits.append(word[:i] + neighbor + word[i+1:])\n    return set(edits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:59:06.247246Z","iopub.execute_input":"2025-02-19T13:59:06.247636Z","iopub.status.idle":"2025-02-19T13:59:06.271829Z","shell.execute_reply.started":"2025-02-19T13:59:06.247604Z","shell.execute_reply":"2025-02-19T13:59:06.270757Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"def bigram_probability(bigram):\n    \"\"\"Calculate the probability of a bigram.\"\"\"\n    unigram = bigram[0]\n    bigram_count = bigram_counts[bigram]\n    unigram_count = unigram_counts[unigram]\n    # print('From bigram\\n',bigram, '\\n', unigram, '\\n')\n    # print(bigram_count, unigram_count)\n    return bigram_count / unigram_count if unigram_count > 0 else 0\n\n\ndef trigram_probability(trigram):\n    \"\"\"Calculate the probability of a trigram.\"\"\"\n    bigram = trigram[:2]\n    trigram_count = trigram_counts[trigram]\n    bigram_count = bigram_counts[bigram]\n    # print('From trigram\\n',trigram, '\\n', bigram, '\\n')\n    # print(trigram_count, bigram_count)\n    return trigram_count / bigram_count if bigram_count > 0 else 0\n\n\ndef candidates(word, prev_word, next_word):\n    \"\"\"Generate candidate corrections for `word` given its preceding word.\"\"\"\n    known_words = known([word]) or known(edits1(word)) or known(edits2(word)) or known(keyboard_edits(word))\n    candidates = [(candidate, trigram_probability((prev_word, candidate, next_word))+bigram_probability((prev_word, candidate))) for candidate in known_words]\n    # print(candidates)\n    return sorted(candidates, key=lambda x: x[1], reverse=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:06:53.957613Z","iopub.execute_input":"2025-02-19T14:06:53.957968Z","iopub.status.idle":"2025-02-19T14:06:53.965380Z","shell.execute_reply.started":"2025-02-19T14:06:53.957942Z","shell.execute_reply":"2025-02-19T14:06:53.964310Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"def correct_sentence(sentence):\n    \"\"\"Correct spelling in a sentence.\"\"\"\n    corrected = []\n    for i, word in enumerate(sentence):\n        prev_word = sentence[i-1] if i > 0 else '<START>'\n        next_word = sentence[i+1] if i < len(sentence)-1 else '<END>'\n        candidates_list = candidates(word, prev_word, next_word)\n        if candidates_list:\n            best_candidate, _ = candidates_list[0]\n            corrected.append(best_candidate)\n        else:\n            corrected.append(word)\n    return corrected","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:03:57.699334Z","iopub.execute_input":"2025-02-19T14:03:57.699825Z","iopub.status.idle":"2025-02-19T14:03:57.706158Z","shell.execute_reply.started":"2025-02-19T14:03:57.699793Z","shell.execute_reply":"2025-02-19T14:03:57.704886Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"sentences = [\"i dking aport\", 'dking species']\nfor sentence in sentences:\n    tokens = word_tokenize(sentence.lower())\n    corrected_tokens = correct_sentence(tokens)\n    print( sentence, \"-->\", ' '.join(corrected_tokens))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:06:56.969707Z","iopub.execute_input":"2025-02-19T14:06:56.970030Z","iopub.status.idle":"2025-02-19T14:06:56.978195Z","shell.execute_reply.started":"2025-02-19T14:06:56.970004Z","shell.execute_reply":"2025-02-19T14:06:56.977147Z"}},"outputs":[{"name":"stdout","text":"i dking aport --> i doing sport\ndking species --> dying species\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"## Justify your decisions\n\nWrite down justificaitons for your implementation choices. For example, these choices could be:\n- Which ngram dataset to use\n- Which weights to assign for edit1, edit2 or absent words probabilities\n- Beam search parameters\n- etc.\n\n---","metadata":{"id":"oML-5sJwGRLE"}},{"cell_type":"markdown","source":"#### **Choice of N-gram Dataset**\n\nThe data set was selected as the datasets \"big.txt\" from the Norvig website and dataset \"bigrams.txt\" from the useful data.\n\n- **\"bigrams.txt\"** from the useful data contain ready-made bigrams that are convenient to use for unigrams and bigrams creation.\n\n- **\"big.txt\"** from the Norvig website is suitable for creating unigrams, bigrams, and trigram creation\n\n---\n\n#### **Weights for Edit1, Edit2, and Absent Words Probabilities**\n\n- **Edit1**: It makes correction that require one simple edit: deletion (remove one letter), a transposition (swap two adjacent letters), a replacement (change one letter to another) or an insertion (add a letter).\n\n  The function edits1 returns a set of all the edited strings (whether words or not) that can be made with one simple edit.\n  \n- **Edit2**: It makes corrections that require two simple edits. This opens up a lot more possibilities, but usually few of them are known words.\n  \n    The function edits2 returns a set of all the edited strings (whether words or not) that can be made with two simple edits.\n\n- **Absent Words**: If no valid correction exists in the dictionary, the original word was retained. This avoids introducing incorrect corrections for rare or proper nouns.\n\n---\n\n#### **Beam Search Parameters**\n The pruning mechanism combined with probability-based sorting achieves similar results to beam search without the additional complexity of maintaining a fixed beam width.\n\n---\n\n#### **Probability Calculation**\n- **bigram probability**:  $P(w_t | w_{t-1})$ is calculated as:\n\n\n  $\n  P(w_t | w_{t-1}) = \\frac{C(w_{t-1}, w_t)}{C(w_{t-1})}\n  $\n  \n  where $ C(w_{t-1}, w_t) $ is the count of the bigram and $ C(w_{t-1}) $ is the count of the preceding word.\n\n- **trigram probability**:  $ P(w_t | w_{t-2}, w_{t-1}) $ is calculated as:\n\n  \n  $\n  P(w_t | w_{t-2}, w_{t-1}) = \\frac{C(w_{t-2}, w_{t-1}, w_t)}{C(w_{t-2}, w_{t-1})}\n  $\n\n  where $ C(w_{t-2}, w_{t-1}, w_t) $ is the count of the trigram and $ C(w_{t-2}, w_{t-1}) $ is the count of the preceding bigram.\n\n- **Combination of Bigram and Trigram Probabilities** : To incorporate wider contextual information, the final score for a candidate is the sum of its bigram and trigram probabilities:\n  \n  $\n  \\text{Score}(w_t) = P(w_t | w_{t-1}) + P(w_t | w_{t-2}, w_{t-1})\n  $\n\n\n---\n\n#### **Keyboard Layout Awareness**\n\n- Using the nearest letters of the keyboard layout increases the model's ability to cope with realistic typos.\n","metadata":{"id":"6Xb_twOmVsC6"}},{"cell_type":"markdown","source":"## Evaluate on a test set\n\nYour task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies.","metadata":{"id":"46rk65S4GRSe"}},{"cell_type":"code","source":"import random\nfrom nltk.corpus import words\n\nnltk.download('words')\nenglish_words = set(words.words())\n\n\ndef add_noise(word, error_prob=0.1):\n    \n    if random.random() > error_prob or len(word) <= 1:\n        return word\n\n    operation = random.choice(['delete', 'transpose', 'replace', 'insert'])\n    idx = random.randint(0, len(word) - 1)\n\n    if operation=='delete' and len(word)>1:\n        return word[:idx]+word[idx+1:]\n        \n    elif operation == 'transpose' and idx < len(word) - 1:\n        return word[:idx]+word[idx+1]+word[idx]+word[idx+2:]\n        \n    elif operation == 'replace':\n        new_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n        return word[:idx]+new_char + word[idx+1:]\n        \n    elif operation=='insert':\n        new_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n        return word[:idx]+new_char+word[idx:]\n        \n    return word\n\ndef generate_test_set(clean_sentences, error_prob=0.1):\n    \"\"\"Generate a noisy test set from clean sentences.\"\"\"\n    noisy_sentences = []\n    for sentence in clean_sentences:\n        noisy_sentence = [add_noise(word, error_prob) for word in sentence]\n        noisy_sentences.append(noisy_sentence)\n    return noisy_sentences\n\n\n# Example\nalices_intro = \"\"\"\nAlice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: \nonce or twice she had peeped into the book her sister was reading, but it had no pictures or conversations \nin it, 'and what is the use of a book,' thought Alice 'without pictures or conversations?'\nSo she was considering, in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), \nwhether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when \nsuddenly a White Rabbit with pink eyes ran close by her.'\n\n\"\"\"\n\nclean_sentences=[]\nfor i in alices_intro.split('.'):\n    i = re.sub(r'[^a-zA-Z\\s]', '', i).lower().replace('\\n', '')\n    tokens = word_tokenize(i)\n    if tokens:\n        clean_sentences.append(tokens)\n\n\nnoisy_sentences_low = generate_test_set(clean_sentences, 0.1)\nnoisy_sentences_medium = generate_test_set(clean_sentences, 0.5)\nnoisy_sentences_high = generate_test_set(clean_sentences, 1)","metadata":{"id":"OwZWaX9VVs7B","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:51:08.414069Z","iopub.execute_input":"2025-02-19T15:51:08.414459Z","iopub.status.idle":"2025-02-19T15:51:08.597657Z","shell.execute_reply.started":"2025-02-19T15:51:08.414417Z","shell.execute_reply":"2025-02-19T15:51:08.595667Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package words to /usr/share/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n","output_type":"stream"}],"execution_count":149},{"cell_type":"code","source":"def evaluate_corrector(noisy_sentences, clean_sentences):\n    \"\"\"Evaluate the accuracy of a corrector on a test set.\"\"\"\n    total_words = 0\n    correct_words = 0\n\n    for noisy_sentence, clean_sentence in zip(noisy_sentences, clean_sentences):\n        corrected_sentence = correct_sentence(noisy_sentence)\n        for corrected_word, clean_word in zip(corrected_sentence, clean_sentence):\n            if corrected_word == clean_word:\n                correct_words += 1\n            total_words += 1\n\n    accuracy = correct_words / total_words if total_words > 0 else 0\n    return accuracy\n\n\n# Evaluate both correctors on the test sets\naccuracy_context_sensitive_low = evaluate_corrector(noisy_sentences_low, clean_sentences)\naccuracy_context_sensitive_medium = evaluate_corrector(noisy_sentences_medium, clean_sentences)\naccuracy_context_sensitive_high = evaluate_corrector(noisy_sentences_high, clean_sentences)\n\nprint('Accuracy on 10% of incorrect text:', round(accuracy_context_sensitive_low, 2))\nprint('Accuracy on 50% of incorrect text:', round(accuracy_context_sensitive_medium, 2))\nprint('Accuracy on 100% of incorrect text:', round(accuracy_context_sensitive_high, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:52:57.104448Z","iopub.execute_input":"2025-02-19T15:52:57.104848Z","iopub.status.idle":"2025-02-19T15:52:58.941293Z","shell.execute_reply.started":"2025-02-19T15:52:57.104817Z","shell.execute_reply":"2025-02-19T15:52:58.940239Z"}},"outputs":[{"name":"stdout","text":"Accuracy on 10% of incorrect text: 0.95\nAccuracy on 50% of incorrect text: 0.74\nAccuracy on 100% of incorrect text: 0.52\n","output_type":"stream"}],"execution_count":152},{"cell_type":"markdown","source":"---\n\n**Norwig's evaluator:**\n\n---","metadata":{}},{"cell_type":"code","source":"def unit_tests():\n    \"\"\"\n    Perform unit tests for the spelling corrector.\n    \"\"\"\n    # Test individual word corrections\n    assert correct_sentence(['speling']) == ['spelling']  # insert\n    assert correct_sentence(['korrectud']) == ['corrected']  # replace 2\n    assert correct_sentence(['bycycle']) == ['bicycle']  # replace\n    assert correct_sentence(['inconvient']) == ['inconvenient']  # insert 2\n    assert correct_sentence(['peotry']) == ['poetry']  # transpose\n    assert correct_sentence(['peotryy']) == ['poetry']  # transpose + delete\n    assert correct_sentence(['word']) == ['word']  # known\n    assert correct_sentence(['quintessential']) == ['quintessential']  # unknown\n\n    # Test sentence tokenization\n    assert [word_tokenize('This is a TEST.') == ['this', 'is', 'a', 'test']]\n\n\n    # Test probability calculations\n    def P(word):\n        return unigram_counts[word] / sum(unigram_counts.values())\n\n    assert P('quintessential') == 0\n\n    return \"unit_tests pass\"\n\n\n# Run unit tests\nprint(unit_tests())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:16:21.116132Z","iopub.execute_input":"2025-02-19T15:16:21.116453Z","iopub.status.idle":"2025-02-19T15:16:21.862790Z","shell.execute_reply.started":"2025-02-19T15:16:21.116427Z","shell.execute_reply":"2025-02-19T15:16:21.861784Z"}},"outputs":[{"name":"stdout","text":"unit_tests pass\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"def spelltest(tests, verbose=False):\n    \"\"\"\n    Run correction on all (right, wrong) pairs in the test set and report results.\n    \"\"\"\n    import time\n    start = time.time()\n    \n    if not tests:  # Check if the test set is empty\n        print(\"No test cases provided.\")\n        return\n    \n    good, unknown = 0, 0\n    n = len(tests)\n\n    for right, wrong in tests:\n        corrected = correct_sentence([wrong])[0]  # Correct the word\n        if corrected == right:\n            good += 1\n        else:\n            if right not in unigram_counts:\n                unknown += 1\n            if verbose:\n                print(f\"correction({wrong}) => {corrected} (expected {right})\")\n\n    dt = time.time() - start\n    print(f\"{good / n:.2%} of {n} correct ({unknown / n:.2%} unknown) at {n / dt:.2f} words per second\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Testset(lines):\n    \"\"\"\n    Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\n    \"\"\"\n    result = []\n    lines = lines.split('\\n')\n    for line in lines:\n        parts = line.strip().split(':')\n        if len(parts) == 2:  # Ensure the line has the correct format\n            right = parts[0].strip()\n            wrongs = parts[1].strip().split()\n            for wrong in wrongs:\n                result.append((right, wrong))\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:21:42.359262Z","iopub.execute_input":"2025-02-19T15:21:42.359667Z","iopub.status.idle":"2025-02-19T15:21:42.365835Z","shell.execute_reply.started":"2025-02-19T15:21:42.359637Z","shell.execute_reply":"2025-02-19T15:21:42.364634Z"}},"outputs":[],"execution_count":125},{"cell_type":"code","source":"import requests\n\nurl1='https://norvig.com/spell-testset1.txt'\nurl2='https://norvig.com/spell-testset2.txt'\n\n\ntry:\n    response = requests.get(url1)\n    response.raise_for_status()\nexcept requests.exceptions.RequestException as e:\n    print(f\"Error fetching data: {e}\")\n    exit()\n\ntext_content1 = response.text\n\ntry:\n    response = requests.get(url2)\n    response.raise_for_status()\nexcept requests.exceptions.RequestException as e:\n    print(f\"Error fetching data: {e}\")\n    exit()\n\ntext_content2 = response.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:05:56.245594Z","iopub.execute_input":"2025-02-19T15:05:56.246007Z","iopub.status.idle":"2025-02-19T15:05:56.836969Z","shell.execute_reply.started":"2025-02-19T15:05:56.245975Z","shell.execute_reply":"2025-02-19T15:05:56.835798Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"spelltest(Testset(text_content1), verbose=False)  # Development set\n\nspelltest(Testset(text_content2), verbose=False)  # Final test set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:21:48.767459Z","iopub.execute_input":"2025-02-19T15:21:48.767940Z","iopub.status.idle":"2025-02-19T15:22:11.954686Z","shell.execute_reply.started":"2025-02-19T15:21:48.767910Z","shell.execute_reply":"2025-02-19T15:22:11.953456Z"}},"outputs":[{"name":"stdout","text":"67.41% of 270 correct (6.30% unknown) at 31.31 words per second\n61.75% of 400 correct (11.00% unknown) at 27.48 words per second\n","output_type":"stream"}],"execution_count":126},{"cell_type":"markdown","source":"---\n\n**Received  accuracies:**\n\n---\n\n##### My Solution of Evaluator:\n\nAccuracy on 10% of incorrect text: 95%\n\nAccuracy on 50% of incorrect text: 74%\n\nAccuracy on 100% of incorrect text: 52%\n\n##### The Norvig Corrector's Solution of Evaluator:\n\nSo on the development set we get 67.41% correct, and on the final test set we get 61.75% correct.","metadata":{}},{"cell_type":"markdown","source":"#### Useful resources (also included in the archive in moodle):\n\n1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)","metadata":{}}]}